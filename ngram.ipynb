{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1954642"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('brothers_k.txt') as f:\n",
    "    txt = f.read()\n",
    "len(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1865368"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def clean(text):\n",
    "    pattern = re.compile(r'[^a-zA-Z\\s]')\n",
    "    return re.sub(pattern, '', text)\n",
    "text = clean(txt)\n",
    "text = text[1000:-1000]\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352861 tokens\n",
      "14933 unique tokens\n"
     ]
    }
   ],
   "source": [
    "lst = text.split()\n",
    "print(len(lst),'tokens')\n",
    "from collections import Counter\n",
    "counts = Counter(lst)\n",
    "print(len(counts),'unique tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(t, n):\n",
    "    words = t.split()\n",
    "    ngrams = [words[i:i+n] for i in range(len(words)-n+1)]\n",
    "    return ngrams\n",
    "\n",
    "def get_counts(text,n):\n",
    "\n",
    "    ngrams = generate_ngrams(text,n)\n",
    "    ngrams_str = [' '.join(ngram) for ngram in ngrams]\n",
    "# print(ngrams_str[:10])\n",
    "    ngrams_counts = Counter(ngrams_str)\n",
    "    return ngrams_counts\n",
    "# ngrams_counts\n",
    "\n",
    "get_counts(text,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_probability(text,n):\n",
    "    print(n,n-1)\n",
    "    ngram_counts = get_counts(text,n)\n",
    "    if n == 1:\n",
    "        return\n",
    "    n_minus_1_counts = get_counts(text,n-1)\n",
    "    # print('hi',n_minus_1_counts)\n",
    "    print(ngram_counts == n_minus_1_counts)\n",
    "    probs = {}\n",
    "    for k in ngram_counts:\n",
    "        n_minus_1 = ' '.join(k.split()[:-1])\n",
    "        if n_minus_1 in n_minus_1_counts:\n",
    "            probs[k] = ngram_counts[k] / n_minus_1_counts[n_minus_1]\n",
    "        else:\n",
    "            probs[k] = 0.000001\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = estimate_probability(text,3)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the even imagine\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_text(probs, seed, max_length=100, stop_token=None):\n",
    "    text = seed.split()\n",
    "    prefix = seed\n",
    "    \n",
    "    while len(text) < max_length:\n",
    "        next_token = sample_next_token(probs, prefix)\n",
    "        if next_token == stop_token:\n",
    "            break        \n",
    "        text.append(next_token)        \n",
    "        prefix = ' '.join(text[-(len(prefix.split()) - 1):])\n",
    "    \n",
    "    generated_text = ' '.join(text)\n",
    "    return generated_text\n",
    "\n",
    "def sample_next_token(probs, prefix):\n",
    "    candidate_ngrams = [ngram for ngram in probs.keys() if ngram.startswith(prefix)]\n",
    "    \n",
    "    if candidate_ngrams:\n",
    "        probabilities = [probs[ngram] for ngram in candidate_ngrams]        \n",
    "        next_ngram = random.choices(candidate_ngrams, weights=probabilities)[0]\n",
    "        return next_ngram.split()[-1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "seed = \"in the\"\n",
    "generated_text = generate_text(probs, seed, max_length=100)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'of the': 1460,\n",
    "#          'in the': 1313,\n",
    "#          'to the': 915,\n",
    "#          'he had': 749,\n",
    "#          'on the': 712,\n",
    "#          'he was': 659,\n",
    "#          'I am': 658,\n",
    "#          'that he': 649,\n",
    "#          'at the': 594,\n",
    "#          'for the': 495,\n",
    "#          'in his': 470,\n",
    "#          'it was': 454,\n",
    "#          'in a': 441,\n",
    "#          'with a': 422,\n",
    "#          'of his': 417,\n",
    "#          'to be': 405,\n",
    "#          'and the': 401,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
